\documentclass[12pt]{article}
\usepackage[letterpaper,top=1in,bottom=1in,left=1.25in,right=1.25in]{geometry}
\usepackage{times}       % Use Times or Times New Roman font
\usepackage{setspace}    % For single spacing
\usepackage{titlesec}    % For custom section headings
\usepackage{footmisc}    % For footnotes

\singlespacing

\setlength{\parindent}{0pt}
\setlength{\parskip}{\baselineskip}

\titleformat{\section}{\bfseries\fontsize{16}{19}\selectfont}{\thesection}{1em}{}
\titlespacing{\section}{0pt}{2\baselineskip}{\baselineskip}
\titleformat{\subsection}{\bfseries\fontsize{14}{17}\selectfont}{\thesubsection}{1em}{}
\titlespacing{\subsection}{0pt}{2\baselineskip}{\baselineskip}
\titleformat{\subsubsection}{\bfseries\fontsize{12}{14}\selectfont}{\thesubsubsection}{1em}{}
\titlespacing{\subsubsection}{0pt}{2\baselineskip}{\baselineskip}

\begin{document}

\thispagestyle{empty} 

\begin{center}
    \vspace*{1.5in}
    {\fontsize{18}{22}\selectfont \textbf{Enhancing Collaboration in Multi-Agent Environments with Attention-Based Actor-Critic Policies}}\\[2\baselineskip]

    % Author info: 14 point, centered
    {\fontsize{14}{17}\selectfont Hugo Garrido-Lestache\footnote{Primary Author}, Jeremy Kedziora\footnote{Advisor}}\\
    {\fontsize{14}{17}\selectfont Department of Computer Science and Software Engineering}\\
    {\fontsize{14}{17}\selectfont Milwaukee School of Engineering}\\
    {\fontsize{14}{17}\selectfont Milwaukee, WI, 53202}\\
    {\fontsize{14}{17}\selectfont \{garrido-lestacheh, kedziora\}@msoe.edu}\\[2\baselineskip]

    {\bfseries \fontsize{16}{19}\selectfont Abstract}\\[1\baselineskip]

    \parbox{0.85\textwidth}{
        \fontsize{12}{14}\selectfont
        Collaboration is essential in solving complex real-world problems, as it enables tasks to be completed more efficiently and leverages the diverse perspectives and skillsets of team members.
        Multi-Agent Reinforcement Learning (MARL) can be utilized to train agents in environments where they must collaborate to achieve a common goal. 
        MARL is challenging due to non-stationarity introduced into the environment by multiple agents learning simultaneously and its development has mainly focused on managing these challenges without any special focus on collaboration. 
        Recent work on MARL has introduced the use of an attention mechanism in the critic of the Actor-Critic architecture that allows the critic to select relevant information from the other agents' observations, promoting better learning of the value function.
        In this paper, we study the impact of the attention mechanism on the quality of learned collaborative policies. 
        We propose a new actor-critic architecture that incorporates an attention mechanism in the actor to model collaboration directly in the learned policies.  
        We evaluate this architecture on a simulation of a soccer game that features competition between teams of collaborators and compare it to current state-of-the-art in MARL as well as classical reinforcement learning algorithms.
        
    }
\end{center}

% After the title/abstract page, move to a new page for the main body
\clearpage

%---------------------------------------------------------------------
% BODY: START PAGE NUMBERING AT 1
%---------------------------------------------------------------------
\setcounter{page}{1}

\section{References}

[1] Shariq Iqbal and Fei Sha, "Actor-Attention-Critic for Multi-Agent Reinforcement Learning," CoRR, vol. abs/1810.02912, 2018. Available: http://arxiv.org/abs/1810.02912

\end{document}