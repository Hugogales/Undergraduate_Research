{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Results:\n",
      "      Team1   Team2  Winner\n",
      "0    Team_1  Team_6    Draw\n",
      "1    Team_5  Team_2    Draw\n",
      "2    Team_5  Team_1    Draw\n",
      "3    Team_2  Team_1  Team_1\n",
      "4    Team_5  Team_2  Team_5\n",
      "..      ...     ...     ...\n",
      "995  Team_5  Team_2  Team_5\n",
      "996  Team_2  Team_3  Team_2\n",
      "997  Team_3  Team_6  Team_6\n",
      "998  Team_1  Team_2  Team_1\n",
      "999  Team_1  Team_6  Team_1\n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "\n",
      "Final Team Rankings:\n",
      "     Team  Rating_Mean  Rating_StdDev  TrueSkill_Score\n",
      "4  Team_5    43.526834       1.537115        38.915490\n",
      "0  Team_1    33.456835       1.205217        29.841183\n",
      "5  Team_6    25.753140       1.154580        22.289400\n",
      "1  Team_2    18.257247       1.177086        14.725988\n",
      "3  Team_4    10.663600       1.248609         6.917774\n",
      "2  Team_3    -0.500104       1.573035        -5.219208\n"
     ]
    }
   ],
   "source": [
    "# Install the trueskill library if you haven't already\n",
    "# !pip install trueskill\n",
    "\n",
    "import trueskill\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the TrueSkill environment\n",
    "ts = trueskill.TrueSkill(draw_probability=0.1)  # Adjust draw probability as needed\n",
    "\n",
    "# Define the number of teams and matches\n",
    "NUM_TEAMS = 6\n",
    "NUM_MATCHES = 1000\n",
    "\n",
    "# Initialize teams with default ratings\n",
    "teams = {}\n",
    "for i in range(1, NUM_TEAMS + 1):\n",
    "    team_name = f\"Team_{i}\"\n",
    "    teams[team_name] = ts.Rating()\n",
    "\n",
    "# Function to simulate a match between two teams\n",
    "def simulate_match(ts_env, team1, team2):\n",
    "    # Get the current ratings\n",
    "    rating1 = teams[team1]\n",
    "    rating2 = teams[team2]\n",
    "    \n",
    "    # Calculate each team's performance by sampling from their rating distributions\n",
    "    perf1 = ts_env.expose(rating1)\n",
    "    perf2 = ts_env.expose(rating2)\n",
    "    \n",
    "    # Determine the outcome\n",
    "    if perf1 > perf2:\n",
    "        # Team1 wins\n",
    "        ranks = [0, 1]\n",
    "    elif perf1 < perf2:\n",
    "        # Team2 wins\n",
    "        ranks = [1, 0]\n",
    "    else:\n",
    "        # Draw\n",
    "        ranks = [0, 0]\n",
    "    \n",
    "    # Update the ratings\n",
    "    new_ratings = ts_env.rate([ [rating1], [rating2] ], ranks)\n",
    "    teams[team1] = new_ratings[0][0]\n",
    "    teams[team2] = new_ratings[1][0]\n",
    "    \n",
    "    # Return the outcome\n",
    "    return {\n",
    "        'Team1': team1,\n",
    "        'Team2': team2,\n",
    "        'Team1_Rating': teams[team1],\n",
    "        'Team2_Rating': teams[team2],\n",
    "        'Winner': team1 if ranks[0] == 0 and ranks[1] == 1 else (team2 if ranks[0] == 1 and ranks[1] == 0 else 'Draw')\n",
    "    }\n",
    "\n",
    "# Simulate matches\n",
    "match_results = []\n",
    "for _ in range(NUM_MATCHES):\n",
    "    # Randomly select two different teams\n",
    "    team1, team2 = random.sample(list(teams.keys()), 2)\n",
    "    result = simulate_match(ts, team1, team2)\n",
    "    match_results.append(result)\n",
    "\n",
    "# Create a DataFrame to display the match results\n",
    "df_matches = pd.DataFrame(match_results)\n",
    "\n",
    "# Calculate final ratings and confidence intervals\n",
    "final_ratings = []\n",
    "for team, rating in teams.items():\n",
    "    # The rating object has a mean (mu) and standard deviation (sigma)\n",
    "    # The conservative estimate of skill is called the \"TrueSkill\" score: mu - 3*sigma\n",
    "    trueskill_score = rating.mu - 3 * rating.sigma\n",
    "    final_ratings.append({\n",
    "        'Team': team,\n",
    "        'Rating_Mean': rating.mu,\n",
    "        'Rating_StdDev': rating.sigma,\n",
    "        'TrueSkill_Score': trueskill_score\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to display the final team ratings\n",
    "df_ratings = pd.DataFrame(final_ratings)\n",
    "df_ratings.sort_values(by='TrueSkill_Score', ascending=False, inplace=True)\n",
    "\n",
    "# Display the match results\n",
    "print(\"Match Results:\")\n",
    "print(df_matches[['Team1', 'Team2', 'Winner']])\n",
    "\n",
    "# Display the final team rankings\n",
    "print(\"\\nFinal Team Rankings:\")\n",
    "print(df_ratings[['Team', 'Rating_Mean', 'Rating_StdDev', 'TrueSkill_Score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
